{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aList = [1914, 1957, 1995,\"hello\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in aList:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aList[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aList[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strList = [\"Frank\", \"Cat\", \"Luna\", \"dog\", \"Bella\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in strList:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(strList[2])\n",
    "print(strList[2].upper())\n",
    "print(strList[2].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in strList:\n",
    "    print(item.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now to a scraping example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.sanacory.net/analytics/LIDA/21.04.08/index.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPage = requests.get(url)\n",
    "mySoup = BeautifulSoup(myPage.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySoup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay still a little unclear what's going on!\n",
    "# Let's look at the source code\n",
    "# What are  table, td, tr, span, ...?  \n",
    "# We need a little html lesson first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltds = mySoup.find_all(\"td\")\n",
    "alltds # This gives us a list of all td tags!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for td in alltds:\n",
    "    print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for td in alltds:\n",
    "    print(td.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if I want to collect all names of the Famous Data Scientists\n",
    "alltds = mySoup.find_all(\"td\")\n",
    "\n",
    "for td in alltds:\n",
    "    # if tag has attribute of class\n",
    "    if td.has_attr( \"class\" ):\n",
    "        print(td['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for td in alltds:\n",
    "    # if tag has attribute of class\n",
    "    if td.has_attr(\"class\"):\n",
    "        if (\"name\" in td['class']):\n",
    "            print(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySoup.find_all(\"td\", {\"class\":\"name\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableDA = mySoup.find(\"table\", {\"class\":\"Data Analytics\"})# can also do a find_all\n",
    "tableDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namesDA = tableDA.find_all(\"td\", {\"class\":\"name\"})\n",
    "namesDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in namesDA:\n",
    "    print(tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You all collect the names of the names and description in the data science topics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example (but please don't scrape without permission!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetChairEmail(url = \"\"):\n",
    "    url = \"https://www.oldwestbury.edu/departments/mathematics\"\n",
    "    print(\"==============================================\")\n",
    "    print(url)\n",
    "    print(\"==============================================\")\n",
    "    \n",
    "    myPage = requests.get(url)\n",
    "    mySoup = BeautifulSoup(myPage.text)\n",
    "    \n",
    "    AllOnceAgain = mySoup.find_all('a')+mySoup.find_all('span')\n",
    "    count = 0\n",
    "    for items in AllOnceAgain:\n",
    "        count+=1\n",
    "        if \"@\" in items.text:\n",
    "            print(count, items.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at https://www.oldwestbury.edu/departments/mathematicsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetChairEmail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Permission first\n",
    "\n",
    "Some websites will block if you try to scrape \n",
    "and some are extremely helpful by offering an API!\n",
    "\n",
    "Tune in next semester where we look at the Zillow.com API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at this link\n",
    "\n",
    "https://www.google.com/search?q=math+department+stanford+University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = \"https://www.google.com/search?q=math+department+stanford+University\"\n",
    "\n",
    "myPage2 = requests.get(url2)\n",
    "mySoup2 = BeautifulSoup(myPage2.text, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySoup2 # just try to find the link!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another warning.  Watch out for hidden characters and unicode oddities, whitespace and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Title of each book and link\n",
    "url3 = \"http://www.gutenberg.org/ebooks/author/6288\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a search for Lewis Carroll\n",
    "http://www.gutenberg.org/ebooks/search/?query=Lewis+Carroll&submit_search=Search\n",
    "\n",
    "Can you write a search and downlaod all of the books for the following list of authors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_authors = [\"Anne Bronte\", \"Emily Bronte\", \"Charlotte Bronte\",\n",
    "                   \"Joseph Conrad\", \"George Bernard Shaw\", \n",
    "                   \"Oscar Wilde\", \"Nathaniel Hawthorne\",\n",
    "                   \"Mary Shelley\", \"William Blake\", \"Robert Burns\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for author in list_of_authors:\n",
    "    #do something\n",
    "    print(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# create User-Agent (optional)\n",
    "#headers = {\"User-Agent\": \"Mozilla/5.0 (CrKey armv7l 1.5.16041) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "#                        \"Chrome/31.0.1650.0 Safari/537.36\"}\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (CrKey armv7l 1.5.16041) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                        \"Chrome/31.0.1650.0 Safari/537.36\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get() Request\n",
    "response = requests.get(\"http://pythonjobs.github.io/\", headers=headers)\n",
    "# Store the webpage contents\n",
    "webpage = response.content\n",
    "# Check Status Code (Optional)\n",
    "# print(response.status_code)\n",
    "# Create a BeautifulSoup object out of the webpage content\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "# The logic\n",
    "for job in soup.find_all('section', class_='job_list'):\n",
    "    title = [a for a in job.find_all('h1')]\n",
    "    for n, tag in enumerate(job.find_all('div', class_='job')):\n",
    "        company_element = [x for x in tag.find_all('span', class_='info')]\n",
    "        print(\"Job Title: \", title[n].text.strip())\n",
    "        print(\"Location: \", company_element[0].text.strip())\n",
    "        print(\"Company: \", company_element[3].text.strip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# create User-Agent (optional)\n",
    "#headers = {\"User-Agent\": \"Mozilla/5.0 (CrKey armv7l 1.5.16041) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "#                        \"Chrome/31.0.1650.0 Safari/537.36\"}\n",
    "\n",
    "# get() Request\n",
    "#response = requests.get(\"http://pythonjobs.github.io/\", headers=headers)\n",
    "\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/Led_Zeppelin\")\n",
    "# Store the webpage contents\n",
    "webpage = response.content\n",
    "# Check Status Code (Optional)\n",
    "# print(response.status_code)\n",
    "# Create a BeautifulSoup object out of the webpage content\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n",
    "# The logic\n",
    "for job in soup.find_all('section', class_='job_list'):\n",
    "    title = [a for a in job.find_all('h1')]\n",
    "    for n, tag in enumerate(job.find_all('div', class_='job')):\n",
    "        company_element = [x for x in tag.find_all('span', class_='info')]\n",
    "        print(\"Job Title: \", title[n].text.strip())\n",
    "        print(\"Location: \", company_element[0].text.strip())\n",
    "        print(\"Company: \", company_element[3].text.strip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/Led_Zeppelin_discography\")\n",
    "webpage = response.content\n",
    "soup = BeautifulSoup(webpage, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in soup.find_all('section', class_='job_list'):\n",
    "    title = [a for a in job.find_all('h1')]\n",
    "    for n, tag in enumerate(job.find_all('div', class_='job')):\n",
    "        company_element = [x for x in tag.find_all('span', class_='info')]\n",
    "        print(\"Job Title: \", title[n].text.strip())\n",
    "        print(\"Location: \", company_element[0].text.strip())\n",
    "        print(\"Company: \", company_element[3].text.strip())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in soup.find_all('table'):\n",
    "    print(\"Class: \", t)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(soup.find_all('table')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist = list(soup.find_all('table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alist[0].find_all('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all('table'):\n",
    "    print(tag.text[0:22])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all('table'):\n",
    "    if tag.text[0:22] == 'List of studio albums':\n",
    "        print(\"Hello\")\n",
    "#It doesn't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all('table'):\n",
    "    if tag.text[1:22] == 'List of studio albums':\n",
    "        for tr in tag.find_all(\"tr\"):\n",
    "            print(tr.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all('table'):\n",
    "    if tag.text[1:22] == 'List of studio albums':\n",
    "        for tr in tag.find_all(\"tr\"):\n",
    "            print(tr.find_all('th')[0].text, )\n",
    "            \n",
    "            if tr.find_all('td'):\n",
    "                print(tr.find_all('td')[0].text)\n",
    "                print(tr.find_all('td')[1].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in soup.find_all('table'):\n",
    "    if tag.text[1:22] == 'List of studio albums':\n",
    "        for tr in tag.find_all(\"tr\")[2:10]:\n",
    "            print('Album Title:  ',tr.find_all('th')[0].text.strip(), )\n",
    "            \n",
    "            if tr.find_all('td'):\n",
    "                rd = tr.find_all('td')[0].text[13:]\n",
    "                rdend = max(rd.find('196')+4,rd.find('197')+4)\n",
    "                print(\"Release Date: \", rd[:rdend].strip())\n",
    "                print(\"UK Chart Rank:\", tr.find_all('td')[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
